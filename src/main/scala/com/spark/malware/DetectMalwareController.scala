package com.spark.malware

import org.apache.spark._
import org.apache.spark.mllib.linalg.{Matrix, SingularValueDecomposition, Vector, Vectors}
import org.apache.spark.mllib.linalg.distributed.RowMatrix
import org.apache.spark.rdd.RDD
/**
  * Created by sparknode on 11/11/16.
  */
object DetectMalwareController {

  def main(args: Array[String]) {
    val inputFile = args(0)
    val outputFile = args(1)

    val conf = new SparkConf().setAppName("DetectMalwareController")
    // Create a Scala Spark Context.
    val sparkContext = new SparkContext(conf)
    // Load our input data.
    val input =  Utilities.getRDD(inputFile, sparkContext)

    val data = Array(
      //Vectors.sparse(5, Seq((1, 1.0), (3, 7.0))),
      Vectors.dense(2.0, 0.0, 3.0, 4.0, 5.0),
      Vectors.dense(4.0, 0.0, 0.0, 6.0, 7.0))

    for( d <- data ) {
      println(d)
    }

    val dataRDD = sparkContext.parallelize(data, 2)

    val mat: RowMatrix = new RowMatrix(dataRDD)

    // Compute the top 5 singular values and corresponding singular vectors.
    val svd: SingularValueDecomposition[RowMatrix, Matrix] = mat.computeSVD(5, computeU = true)
    val U: RowMatrix = svd.U // The U factor is a RowMatrix.
    val s: Vector = svd.s // The singular values are stored in a local dense vector.
    val V: Matrix = svd.V // The V factor is a local dense matrix.

    val collect = U.rows.collect()
    println("U factor is:")
    collect.foreach { vector => println(vector) }
    println(s"Singular values are: $s")
    println(s"V factor is:\n$V")

    //Extract N-grams
    //Select Features
    //Build Training dataset
    //Generate feature set
    //Build Model
    //Build Testing dataset using Feature set and test data
    //Predict files
  }

}
