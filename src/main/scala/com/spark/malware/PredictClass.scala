package com.spark.malware

import org.apache.spark.ml.classification.RandomForestClassificationModel
import org.apache.spark.mllib.classification.{SVMModel, SVMWithSGD}
import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics
import org.apache.spark.rdd.RDD
import org.apache.spark.mllib.regression.LabeledPoint
import org.apache.spark.mllib.tree.model.{DecisionTreeModel, RandomForestModel}

/**
  * Created by ram on 12/8/16.
  */
object PredictClass {

  def predict( model: Any, testData: RDD[LabeledPoint] ) = {

    var predictionAndLabels:RDD[(Double, Double)] = RunParameters.sparkContext.emptyRDD
    // predict class label for test instances
    if( BuildModel.getModelType.equals(Constants.DECISION_TREE) ) {

      val namedModel: DecisionTreeModel = model.asInstanceOf[DecisionTreeModel]

      val labelAndPreds: RDD[(Double, Double)] = testData.map { point =>
        val prediction = {
          namedModel.predict(point.features)
        }
        (point.label, prediction)
      }

      predictionAndLabels = labelAndPreds

    }
    else if ( BuildModel.getModelType.equals(Constants.SUPPORT_VECTOR_MACHINE)) {

      val namedModel : SVMModel = model.asInstanceOf[SVMModel]
      // Compute raw scores on the test set.
      val scoreAndLabels: RDD[(Double, Double)] = testData.map { point =>
        val score = namedModel.predict(point.features)
        (score, point.label)
      }

      predictionAndLabels = scoreAndLabels
    }
    else if ( BuildModel.getModelType.equals(Constants.RANDOM_FOREST)) {

      val namedModel : RandomForestModel = model.asInstanceOf[RandomForestModel]
      // Compute raw scores on the test set.
      val scoreAndLabels: RDD[(Double, Double)] = testData.map { point =>
        val score = namedModel.predict(point.features)
        (score, point.label)
      }

      predictionAndLabels = scoreAndLabels
    }

    val accuracy = predictionAndLabels.filter(r => r._1 == r._2).count().toDouble / testData.count()
    //Results
    println(" Model: Accuracy =		" + "%2.2f".format(accuracy * 100) + " %")

    predictionAndLabels
  }

  def computeAndPrintMetrics(predictionAndLabels : RDD[(Double, Double)]) = {

    // Instantiate metrics object
    val metrics = new BinaryClassificationMetrics(predictionAndLabels)

    // Precision by threshold
    val precision = metrics.precisionByThreshold
    precision.foreach { case (t, p) =>
      println(s"Threshold: $t, Precision: $p")
    }

    // Recall by threshold
    val recall = metrics.recallByThreshold
    recall.foreach { case (t, r) =>
      println(s"Threshold: $t, Recall: $r")
    }

    // Precision-Recall Curve
    val PRC = metrics.pr

    // F-measure
    val f1Score = metrics.fMeasureByThreshold
    f1Score.foreach { case (t, f) =>
      println(s"Threshold: $t, F-score: $f, Beta = 1")
    }

    val beta = 0.5
    val fScore = metrics.fMeasureByThreshold(beta)
    f1Score.foreach { case (t, f) =>
      println(s"Threshold: $t, F-score: $f, Beta = 0.5")
    }

    // AUPRC
    val auPRC = metrics.areaUnderPR
    println("Area under precision-recall curve = " + auPRC)

    // Compute thresholds used in ROC and PR curves
    val thresholds = precision.map(_._1)

    // ROC Curve
    val roc = metrics.roc

    // AUROC
    val auROC = metrics.areaUnderROC
    println("Area under ROC = " + auROC)

  }
}
