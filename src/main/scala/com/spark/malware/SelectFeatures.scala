package com.spark.malware

import org.apache.spark.rdd.RDD

/**
  * Created by ram on 11/23/16.
  */
object SelectFeatures {

  var selectionMethod = RunParameters.DEFAULT_FEATURE_SELECTION_METHOD

  def setMethod( method : String) = {
      this.selectionMethod = method
  }

  def generateFeatureSet( N_gram_records : RDD[(String, String)]) = {

    if(selectionMethod.equals(Constants.INFORMATION_GAIN) ) {
      val featureSet = selectUsingInformationGain( N_gram_records )
    }
    else if(selectionMethod.equals(Constants.PRINCIPAL_COMPONENT_ANALYSIS) ) {

    }
    else if(selectionMethod.equals(Constants.SINGULAR_VALUE_DECOMPOSITION) ) {

    }

  }

  def selectUsingInformationGain( NgramRecords : RDD[(String, String)]) = {

    println("information Gain selected")
    //(ngram, classLabel, class0Count, class1Count)
    val NgramsWithInitialClassCounts = NgramRecords.map( record=> ( record._1, record._2, 0 , 0 )  )
    val NgramsWithClassCounts = NgramsWithInitialClassCounts.map( record => {
      if( record._2.equals(Constants.CLASS_ZERO) ) {
        ( record._1, record._2, (record._3.toInt+1).toString, record._4 )
      }
      else {
        ( record._1, record._2, record._3, (record._4.toInt+1).toString )
      }
    } )

    //val NgramClassZeroCount = N_gram_records.filter( x => x._2.equals(Constants.CLASS_ZERO)).map(x => (x._1, 1)).reduceByKey(_+_)
    //val NgramClassOneCount = N_gram_records.filter( x => x._2.equals(Constants.CLASS_ONE)).map(x => (x._1, 1)).reduceByKey(_+_)

    //Ngram_class0.join(Ngram_class1).map()
    val total_class0_files = 50
    val total_class1_files = 50

    NgramsWithClassCounts.map( record => ( record._1, ( record._2, record._3, record._4 )  )).foreach(println)

  }

  def getFeatureSet() = {

  }
}
