package com.spark.malware

import org.apache.spark.rdd.RDD


/**
  * Created by ram on 11/23/16.
  */
object SelectFeatures {

  var selectionMethod = RunParameters.DEFAULT_FEATURE_SELECTION_METHOD
  var featureSet : RDD[String] = RunParameters.sparkContext.emptyRDD

  def setMethod( method : String) = {
      this.selectionMethod = method
  }

  def setFeatureSet( features : RDD[String] ) = {
    this.featureSet = features
  }

  def generateFeatureSet( N_gram_records : RDD[(String, String)]) = {

    if(selectionMethod.equals(Constants.INFORMATION_GAIN) ) {
      val featureSet = selectUsingInformationGain( N_gram_records )
    }
    else if(selectionMethod.equals(Constants.PRINCIPAL_COMPONENT_ANALYSIS) ) {

    }
    else if(selectionMethod.equals(Constants.SINGULAR_VALUE_DECOMPOSITION) ) {

    }

    featureSet
  }

  def computeInformationGain( classCounts : (Int, Int) ): Double = {
    val classZeroCount = classCounts._1
    val classOneCount = classCounts._2

    val probabilityVngZero = (Constants.TOTAL_INPUT_FILES - classZeroCount - classOneCount).toDouble / Constants.TOTAL_INPUT_FILES
    val probabilityVngOne = (classZeroCount + classOneCount).toDouble / Constants.TOTAL_INPUT_FILES

    val probabilityClassZero = Constants.TOTAL_BENIGN_FILES.toDouble / Constants.TOTAL_INPUT_FILES
    val probabilityClassOne = Constants.TOTAL_MALICIOUS_FILES.toDouble / Constants.TOTAL_INPUT_FILES

    val probabilityClassZeroVngZero = (Constants.TOTAL_BENIGN_FILES - classZeroCount).toDouble / Constants.TOTAL_BENIGN_FILES
    val probabilityClassZeroVngOne = classZeroCount.toDouble  / Constants.TOTAL_BENIGN_FILES

    val probabilityClassOneVngZero = ( Constants.TOTAL_MALICIOUS_FILES - classOneCount).toDouble / Constants.TOTAL_MALICIOUS_FILES
    val probabilityClassOneVngOne =classOneCount.toDouble  / Constants.TOTAL_MALICIOUS_FILES

    var informationGain = 0.0

    if( probabilityVngZero > 0 ) {

      var logProbabilityClassZeroVngZero = Math.log(probabilityClassZeroVngZero / (probabilityClassZero * probabilityVngZero))
      logProbabilityClassZeroVngZero = if (logProbabilityClassZeroVngZero == Double.NegativeInfinity) 0.0 else logProbabilityClassZeroVngZero

      var logProbabilityClassOneVngZero = Math.log(probabilityClassOneVngZero / (probabilityClassOne * probabilityVngZero))
      logProbabilityClassOneVngZero = if (logProbabilityClassOneVngZero == Double.NegativeInfinity) 0.0 else logProbabilityClassOneVngZero

      var logProbabilityClassZeroVngOne = Math.log(probabilityClassZeroVngOne / (probabilityClassZero * probabilityVngOne))
      logProbabilityClassZeroVngOne = if (logProbabilityClassZeroVngOne == Double.NegativeInfinity) 0.0 else logProbabilityClassZeroVngOne

      var logProbabilityClassOneVngOne = Math.log(probabilityClassOneVngOne / (probabilityClassOne * probabilityVngOne))
      logProbabilityClassOneVngOne = if (logProbabilityClassOneVngOne == Double.NegativeInfinity) 0.0 else logProbabilityClassOneVngOne

      informationGain = (probabilityClassZeroVngZero * logProbabilityClassZeroVngZero) +
        (probabilityClassZeroVngOne * logProbabilityClassZeroVngOne) +
        (probabilityClassOneVngZero * logProbabilityClassOneVngZero) +
        (probabilityClassOneVngOne * logProbabilityClassOneVngOne)
    }

    informationGain
  }

  def selectUsingInformationGain( NgramCollection : RDD[(String, String)]) = {

    val NgramRecords = NgramCollection
      .map( x=> ( x._1, x._2.split(Constants.SYMBOL_COLON)(2) ))

    val NgramsWithClassCounts = NgramRecords
      .map( record => ((record._1, record._2), 1 ))
      .reduceByKey(_+_)
      .map( record => ( record._1._1, (record._1._2.toInt, record._2) ))
      .groupByKey()
      .mapValues(list => {
        var classZeroCount = 0
        var classOneCount = 0
        for( row <- list ) {
          if( row._1 == 0 ) {
            classZeroCount = row._2
          }
          else {
            classOneCount = row._2
          }
        }
        (classZeroCount, classOneCount)
      } )

    val NgramWithInformationGain = NgramsWithClassCounts
      .map( record => (record._1, computeInformationGain( record._2 ) ) )
      .sortBy( record => record._2, false)
      //.filter( record => record._2 > Constants.INFORMATION_GAIN_THRESHOLD )
    //NgramWithInformationGain.saveAsTextFile("/home/ram/output")
    //val selectedNgrams = NgramWithInformationGain.map( record => record._1 )
    val selectedNgrams = RunParameters.sparkContext.parallelize(NgramWithInformationGain.map( record => record._1 ).take(25))
    this.setFeatureSet(selectedNgrams)

    selectedNgrams
  }

  def getFeatureSet() = {
    this.featureSet
  }
}
